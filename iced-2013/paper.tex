\documentclass[conference]{IEEEtran}

% Use of outside images
\usepackage{graphicx} 
% Use text inside euqations
\usepackage{amsmath}

\usepackage{balance}
\usepackage{float}
\floatstyle{plaintop}
\restylefloat{table}

% Correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% Begin the paper here
\begin{document}


% Paper title
% Can use linebreaks \\ within to get better formatting as desired
\title{Indirect Conflicts: An Exploration and Discussion of Tools, Process, and Developer Insight}

\author{\IEEEauthorblockN{Jordan Ell}
\IEEEauthorblockA{University of Victoria,
Victoria, Canada \\ jell@uvic.ca}
IEEEauthorblockN{Daniela Damian}
\IEEEauthorblockA{University of Victoria,
Victoria, Canada \\ danielad@csc.uvic.ca}
}

% Make the title area
\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}
\label{sec:intro}

\section{Related Work}

\section{Methodology}

Our study was performed in two parts. First, a round of semi-structured interviews were conducted which 
addressed the larger who, what, when, where, and how about indirect conflicts. Secondly, a survey was given
out which was used to confirm what was learned from the interviews on a larger sample size as well as get
a larger opinion base on general issues.

\subsection{Interview Participants}

We selected our interview participants from a large breadth of both open and closed source software development companies
and projects. The population which participated in our interview came from the following software groups: 
IBM, Mozilla, The GNOME Project, Microsoft Corporation, Subnet Solutions, Ruboss Technology Corporation, 
Amazon, Exporq Oy, Kano Apps, Fireworks Design, James Evans and Associates, and Frost Tree Games. 
Our participants we chosen based on their direct involvement in the actual writing of software for
their respective companies or projects. These participants' software development titles included: senior developer,
lead developer, software developer, software developer in test, and junior developer.
In addition to software development, some participants were also chosen based on their previous experience
of software development as well as their current experience with project management at some capacity. These management
type participants involved in project planning to some capacity between technical architecture, project maintainer,  
chief technical officer, or program manager.

\subsection{Interview Procedure}

Participants were invited to participate in the interviews by email and were sent a single reminder email one week
after the initial invitation if no response had been made. We directly emailed 22 participants and ended up conducting
19 interviews. Interviews were conducted in person when possible and recorded for audio content only. When in person
interviews were not possible, one of Skype or Google Hangout was used with audio and video being recorded but only
audio being stored for future use. We were quite pleased with the response rate to our initial invitation emails as
our breadth of participants was rather large spanning multiple open and closed source project and our interview 
answer saturation was quite high (to be seen in Section~\ref{sec:rnd}). However, we were disappointed in our word
of mouth campaign. We had asked several participants to pass along our interviews invitations to other members of
their respective organizations but did not receive any additional participants through this method.

Interview participants first answered a number of structured demographic items. Next, participants were 
asked to describe various software development processes they use or encounter in their current working
environment. These structured process questions were used for later analysis to provided context to
any answer for questions that involve indirect conflicts. They next were engaged in a
semi-structured round of questions pertaining to 12 categories of questions. Each of the categories was used as a
point of aggregation for later analysis as a way of answering the X research questions laid out in 
Section~\ref{sec:intro}. While each of the 12 question categories had a number of starter questions, interviews 
largely became discussions of developer experience and opinion as opposed to direct answers to any specific question.
In general, once the category was explained to the participant, little prompting was necessary as the participant
would jump right into an experience, or issue he or she had with the question or category. However, not all
participants had strong opinions or any experience on every category mentioned. For these participants, answers 
to the specific categories were not required or pressed upon. We attribute any non answer by a participant to
either lack of knowledge in their current project pertaining to the category or lack of experience in terms of
being apart of any one software project for extended periods of time. We account for these non answers
in our analysis as seen in Section~\ref{sec:rnd}. Interviews lasted 
from 15 minutes up to 75 minutes. The length of the interview largely depended on the amount of experience the
participant had in software development as they were able to give more experiences and more informed opinions.

After the interviews, we extracted a list of answers, opinions, and experiences for each of the 12 categorical
question fields. We combined commonly mentioned opinions and answers where possible, and noted where experiences
with indirect conflicts from participants were similar but generally kept the experiences tied to the individual.
Where more direct answers were given, we used the wording of our participants rather than our own descriptive 
aggregations. The results of this preliminary analysis was a list of short hypotheses supported by direct developer
experience and opinion for the 12 categories. These hypotheses were then used as a template for creating the
second step survey, in order to further test the answers given by interview participants and validate any possible
conclusions to be drawn.

\subsection{Survey Participants}

We selected our survey participants from a similar breadth of open and closed source software development 
companies and projects as the interviews participants with two large exceptions. The software organizations
that remained the same between interview and survey were: Mozilla, The GNOME Project, Microsoft Corporation, 
Subnet Solutions, Ruboss Technology Corporation, Amazon, Kano Apps, Fireworks Design, and Frost Tree Games.
However, participants who took part in the round of interviews were not asked to participate in the surveys but
rather to act as a contact point for other developers in their team, project, or organization who may be interested
in completing the survey. Aside from this aforementioned list, two large groups of developers were asked to
participate as well, these being GitHub users as well as Apache Software Foundation (Apache) developers. The GitHub
users were selected based on their large amounts of development activity on GitHub and the Apache developers
were selected based on their software development participation on specific projects known to be used heavily
by other organizations and projects.

\subsection{Survey Procedure}

The created survey was based off of the 12 categorical hypotheses given by the round of interviews. The survey
was designed to test these hypotheses and to acquire a larger sample size of developers who may have similar
or different opinions from those already acquired from the interviews. The survey went through two rounds of
piloting. Each pilot round consisted of five participants, who were previously interviewed, completing the survey
with feedback given at the end. The previous interview participants were selected based on their domain knowledge
expertise with indirect conflicts in order to provide what we think would be amount to better feedback and resulting
in a more polished survey. The final survey consisted of 2 multiple choice, 3 level of agreement,
6 level of use, and 9 short answer questions. Each non demographic question was made optional as it was shown 
through the interviews that some questions require more experience from participants than may be provided.

Survey participants were invited to participate in the survey by email. No reminder email was ever sent as the
survey responses were not connected with the invitation email addresses and thus participants who did respond
could not be removed from a reminder list. We directly emailed 1300 participants and ended with 78 responses
giving a response rate of 6\%. We attribute the low response rate with a couple of factors. One, the surveys
were conducted during the months of July and August while many participants may be away from their regular positions.
Two, our GitHub and Apache participants could not be verified as to whether or not they actively support the
email addresses used in the invitations. And finally, the survey was considered by some to be long and require
more development experience than may have been typical of some of those invited to participate.

After the survey was closed, preliminary analysis was applied to the short answer questions in the same manor
as the interview responses. We extracted a list of answers, opinions, and experiences for each of the 9 short
answer question fields while combining commonly mentioned answers where possible. The results again from this
preliminary analysis is a list of common and unique hypotheses to each of the 9 short answer questions.

\section{Results and Discussion}
\label{sec:rnd}

\section{Future Work}

\section{Conclusions}

\section{Acknowledgments}

We would sincerely like to thank all participants who were willing to be interviewed or who participated
in completeing our survey. We thank these people for taking time out of their day to participate and for
sharing their developer experience with us. Without these people our research could not have been possible.

%\bibliographystyle{IEEEtran}
%\balance
%\bibliography{paper}

% End of the paper
\end{document}
